{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from time import time\n",
    "from scipy.stats import linregress\n",
    "from lib import misc, utils, app\n",
    "from lib.calib import project_points_fisheye, triangulate_points_fisheye\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOT_DATA_DIR = os.path.join(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Params\n",
    "Define the params in the cell below. Thereafter, run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(ROOT_DATA_DIR, \"2019_03_09\", \"lily\", \"run\")\n",
    "DATA_DIR = os.path.join(ROOT_DATA_DIR, \"2017_08_29\", \"top\", \"jules\", \"run1_1\")\n",
    "\n",
    "start_frame = 50\n",
    "end_frame = 115\n",
    "\n",
    "# DLC p_cutoff - any points with likelihood < dlc_thresh are not trusted in optimisation\n",
    "dlc_thresh = 0.8  # change this only if optimisation result is unsatisfactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= INIT VARS ========\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "assert os.path.exists(DATA_DIR)\n",
    "OUT_DIR = os.path.join(DATA_DIR, 'ekf')\n",
    "DLC_DIR = os.path.join(DATA_DIR, 'dlc')\n",
    "assert os.path.exists(DLC_DIR)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "app.start_logging(os.path.join(OUT_DIR, 'ekf.log'))\n",
    "\n",
    "idx = misc.get_pose_params() # define the indices for the states\n",
    "markers = misc.get_markers() # define DLC labels\n",
    "\n",
    "n_markers = len(markers)\n",
    "n_pose_params = len(idx)\n",
    "n_states = 3*n_pose_params\n",
    "vel_idx = n_states//3\n",
    "acc_idx = n_states*2//3\n",
    "\n",
    "derivs = {'d'+state: vel_idx+idx[state] for state in idx}\n",
    "derivs.update({'d'+state: vel_idx+derivs[state] for state in derivs})\n",
    "idx.update(derivs)\n",
    "\n",
    "# load video info\n",
    "res, fps, tot_frames, _ = app.get_vid_info(DATA_DIR) # path to original videos\n",
    "assert end_frame <= tot_frames\n",
    "\n",
    "# Load extrinsic params\n",
    "k_arr, d_arr, r_arr, t_arr, cam_res, n_cams, scene_fpath = utils.find_scene_file(DATA_DIR)\n",
    "assert res == cam_res\n",
    "camera_params = [[K, D, R, T] for K, D, R, T in zip(k_arr, d_arr, r_arr, t_arr)]\n",
    "\n",
    "# other vars\n",
    "start_frame -= 1 # 0 based indexing\n",
    "assert start_frame >= 0\n",
    "n_frames = end_frame-start_frame\n",
    "sigma_bound = 3\n",
    "max_pixel_err = cam_res[0] # used in measurement covariance R\n",
    "sT = 1.0/fps # timestep\n",
    "\n",
    "# ========= FUNCTION DEFINITINOS ========\n",
    "\n",
    "def h_function(x: np.ndarray, k: np.ndarray, d: np.ndarray, r: np.ndarray, t: np.ndarray):\n",
    "    \"\"\"Returns a numpy array of the 2D marker pixel coordinates (shape Nx2) for a given state vector x and camera parameters k, d, r, t.\n",
    "    \"\"\"\n",
    "    coords_3d = misc.get_3d_marker_coords(x)\n",
    "    coords_2d = project_points_fisheye(coords_3d, k, d, r, t) # Project the 3D positions to 2D\n",
    "    \n",
    "    return coords_2d\n",
    "\n",
    "\n",
    "def predict_next_state(x: np.ndarray, dt: np.float32):\n",
    "    \"\"\"Returns a numpy array of the predicted states for a given state vector x and time delta dt.\n",
    "    \"\"\"\n",
    "    acc_prediction = x[acc_idx:]\n",
    "    vel_prediction = x[vel_idx:acc_idx] + dt*acc_prediction\n",
    "    pos_prediction = x[:vel_idx] + dt*vel_prediction + (0.5*dt**2)*acc_prediction\n",
    "    \n",
    "    return np.concatenate([pos_prediction, vel_prediction, acc_prediction]).astype(np.float32)\n",
    "\n",
    "\n",
    "def numerical_jacobian(func, x: np.ndarray, *args):\n",
    "    \"\"\"Returns a numerically approximated jacobian of func with respect to x.\n",
    "    Additional parameters will be passed to func using *args in the format: func(*x, *args)\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    eps = 1e-3\n",
    "    \n",
    "    fx = func(x, *args).flatten()\n",
    "    xpeturb=x.copy()\n",
    "    jac = np.empty((len(fx), n))\n",
    "    for i in range(n):\n",
    "        xpeturb[i] = xpeturb[i]+eps\n",
    "        jac[:,i] = (func(xpeturb, *args).flatten() - fx)/eps\n",
    "        xpeturb[i]=x[i]\n",
    "        \n",
    "    return jac\n",
    "\n",
    "\n",
    "# ========= LOAD DLC DATA ========\n",
    "\n",
    "# Load DLC 2D point files (.h5 outputs)\n",
    "dlc_2d_point_files = glob(os.path.join(DLC_DIR, '*.h5'))\n",
    "assert(len(dlc_2d_point_files) == n_cams), f\"# of dlc '.h5' files != # of cams in {n_cams}_cam_scene_sba.json\"\n",
    "\n",
    "# Load Measurement Data (pixels, likelihood)\n",
    "points_2d_df = utils.load_dlc_points_as_df(dlc_2d_point_files, verbose=False)\n",
    "\n",
    "points_3d_df = utils.get_pairwise_3d_points_from_df(\n",
    "    points_2d_df[points_2d_df['likelihood']>dlc_thresh], # ignore points with low likelihood\n",
    "    k_arr, d_arr.reshape((-1,4)), r_arr, t_arr,\n",
    "    triangulate_points_fisheye\n",
    ")\n",
    "\n",
    "# Restructure dataframe\n",
    "points_df = points_2d_df.set_index(['frame', 'camera','marker'])\n",
    "points_df = points_df.stack().unstack(level=1).unstack(level=1).unstack()\n",
    "\n",
    "# Pixels array\n",
    "pixels_df = points_df.loc[:, (range(n_cams), markers, ['x','y'])]\n",
    "pixels_df = pixels_df.reindex(columns=pd.MultiIndex.from_product([range(n_cams), markers, ['x','y']]))\n",
    "pixels_arr = pixels_df.to_numpy() #shape - (n_frames, n_cams * n_markers * 2)\n",
    "\n",
    "# Likelihood array\n",
    "likelihood_df = points_df.loc[:, (range(n_cams), markers, 'likelihood')]\n",
    "likelihood_df = likelihood_df.reindex(columns=pd.MultiIndex.from_product([range(n_cams), markers, ['likelihood']]))\n",
    "likelihood_arr = likelihood_df.to_numpy() #shape - (n_frames, n_cams * n_markers * 1)\n",
    "\n",
    "# ========= INITIALIZE EKF MATRICES ========\n",
    "\n",
    "# estimate initial points\n",
    "states = np.zeros(n_states)\n",
    "\n",
    "try:\n",
    "    lure_pts = points_3d_df[points_3d_df[\"marker\"]==\"lure\"][[\"frame\", \"x\", \"y\", \"z\"]].values\n",
    "    lure_x_slope, lure_x_intercept, *_ = linregress(lure_pts[:,0], lure_pts[:,1]) \n",
    "    lure_y_slope, lure_y_intercept, *_ = linregress(lure_pts[:,0], lure_pts[:,2])\n",
    "\n",
    "    lure_x_est = start_frame*lure_x_slope + lure_x_intercept # initial lure x\n",
    "    lure_y_est = start_frame*lure_y_slope + lure_y_intercept # initial lure y\n",
    "\n",
    "    states[[idx['x_l'], idx['y_l']]] = [lure_x_est, lure_y_est]             # lure x & y in inertial\n",
    "    states[[idx['dx_l'], idx['dy_l']]] = [lure_x_slope/sT, lure_y_slope/sT] # lure x & y velocity in inertial\n",
    "except ValueError as e: # for when there is no lure data\n",
    "    print(f\"Lure initialisation error: '{e}' -> Lure states initialised to zero\")\n",
    "\n",
    "points_3d_df = points_3d_df[points_3d_df['frame'].between(start_frame, end_frame-1)]\n",
    "\n",
    "nose_pts = points_3d_df[points_3d_df[\"marker\"]==\"nose\"][[\"frame\", \"x\", \"y\", \"z\"]].values\n",
    "nose_x_slope, nose_x_intercept, *_ = linregress(nose_pts[:,0], nose_pts[:,1]) \n",
    "nose_y_slope, nose_y_intercept, *_ = linregress(nose_pts[:,0], nose_pts[:,2])\n",
    "\n",
    "nose_x_est = start_frame*nose_x_slope + nose_x_intercept # initial nose x\n",
    "nose_y_est = start_frame*nose_y_slope + nose_y_intercept # initial nose y\n",
    "nose_psi_est = np.arctan2(nose_y_slope, nose_x_slope)    # initial yaw angle relative to inertial\n",
    "\n",
    "# INITIAL STATES\n",
    "states[[idx['x_0'], idx['y_0'],idx['psi_0']]] = [nose_x_est, nose_y_est, nose_psi_est] # head x, y & psi (yaw) in inertial\n",
    "states[[idx['dx_0'], idx['dy_0']]] = [nose_x_slope/sT, nose_y_slope/sT]                # head x & y velocity in inertial\n",
    "\n",
    "# INITIAL STATE COVARIANCE P - how much do we trust the initial states\n",
    "# position\n",
    "p_lin_pos = np.ones(3)*3**2                       # Know initial position within 4m\n",
    "p_ang_pos = np.ones(n_pose_params-6)*(np.pi/4)**2 # Know initial angles within 60 degrees, heading may need to change\n",
    "p_lure_pos = p_lin_pos\n",
    "# velocity\n",
    "p_lin_vel = np.ones(3)*5**2                       # Know this within 2.5m/s and it's a uniform random variable\n",
    "p_ang_vel = np.ones(n_pose_params-6)*3**2\n",
    "p_lure_vel = p_lin_vel\n",
    "# acceleration\n",
    "p_lin_acc = np.ones(3)*3**2\n",
    "p_ang_acc = np.ones(n_pose_params-6)*3**2\n",
    "p_ang_acc[10:] = 5**2\n",
    "p_lure_acc = p_lin_acc\n",
    "\n",
    "P = np.diag(np.concatenate([p_lin_pos, p_ang_pos, p_lure_pos,\n",
    "                            p_lin_vel, p_ang_vel, p_lure_vel,\n",
    "                            p_lin_acc, p_ang_acc, p_lure_acc]))\n",
    "\n",
    "# PROCESS COVARIANCE Q - how \"noisy\" the constant acceleration model is\n",
    "qb_list = [\n",
    "    5.0, 5.0, 5.0,    # head x, y, z in inertial\n",
    "    10.0, 10.0, 10.0, # head phi, theta, psi in inertial\n",
    "    5.0, 25.0, 5.0,   # neck phi, theta, psi\n",
    "    50.0,             # front-torso theta\n",
    "    5.0, 50.0, 25.0,  # back torso phi, theta, psi\n",
    "    100.0, 30.0,      # tail base theta, psi\n",
    "    140.0, 40.0,      # tail mid theta, psi\n",
    "    350.0, 200.0,     # l_shoulder theta, l_front_knee theta\n",
    "    350.0, 200.0,     # r_shoulder theta, r_front_knee theta\n",
    "    450.0, 400.0,     # l_hip theta, l_back_knee theta\n",
    "    450.0, 400.0,     # r_hip theta, r_back_knee theta\n",
    "]\n",
    "qb_list += qb_list[0:3] # lure x, y, z in inertial - same as head\n",
    "\n",
    "qb = (np.diag(qb_list)/2)**2\n",
    "Q = np.block([\n",
    "    [sT**4/4 * qb, sT**3/2 * qb, sT**2/2 * qb],\n",
    "    [sT**3/2 * qb, sT**2 * qb, sT * qb],\n",
    "    [sT**2/2 * qb, sT * qb, qb],\n",
    "])\n",
    "\n",
    "# MEASUREMENT COVARIANCE R\n",
    "dlc_cov = 5**2\n",
    "\n",
    "# State prediction function jacobian F - shape: (n_states, n_states)\n",
    "rng = np.arange(n_states - vel_idx)\n",
    "rng_acc = np.arange(n_states - acc_idx)\n",
    "F = np.eye(n_states)\n",
    "F[rng, rng+vel_idx] = sT\n",
    "F[rng_acc, rng_acc+acc_idx] = sT**2/2\n",
    "\n",
    "# Allocate space for storing EKF data\n",
    "states_est_hist = np.zeros((n_frames, n_states))\n",
    "states_pred_hist = states_est_hist.copy()\n",
    "P_est_hist = np.zeros((n_frames, n_states, n_states))\n",
    "P_pred_hist = P_est_hist.copy()\n",
    "\n",
    "t1 = time()\n",
    "print(\"\\nInitialization took {0:.2f} seconds\\n\".format(t1 - t0))\n",
    "\n",
    "# ========= RUN EKF & SMOOTHER ========\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "outliers_ignored = 0\n",
    "\n",
    "for i in range(n_frames):\n",
    "    print(f\"Running frame {i+start_frame+1}\\r\", end='')\n",
    "    \n",
    "    # ========== PREDICTION ==========\n",
    "\n",
    "    # Predict State\n",
    "    states = predict_next_state(states, sT).flatten()\n",
    "    states_pred_hist[i] = states\n",
    "\n",
    "    # Projection of the state covariance\n",
    "    P = F @ P @ F.T + Q\n",
    "    P_pred_hist[i] = P\n",
    "    \n",
    "    # ============ UPDATE ============\n",
    "    \n",
    "    z_k = pixels_arr[i+start_frame]\n",
    "    likelihood = likelihood_arr[i+start_frame]\n",
    "    \n",
    "    # Measurement\n",
    "    H = np.zeros((n_cams*n_markers*2, n_states))\n",
    "    h = np.zeros((n_cams*n_markers*2)) # same as H[:, 0].copy()\n",
    "    for j in range(n_cams):\n",
    "        # State measurement\n",
    "        h[j*n_markers*2:(j+1)*n_markers*2] = h_function(states[:vel_idx], *camera_params[j]).flatten()\n",
    "        # Jacobian - shape: (2*n_markers, n_states)\n",
    "        H[j*n_markers*2:(j+1)*n_markers*2, 0:vel_idx] = numerical_jacobian(h_function, states[:vel_idx], *camera_params[j])\n",
    "    \n",
    "    # Measurement Covariance R\n",
    "    bad_point_mask = np.repeat(likelihood<dlc_thresh, 2)\n",
    "    dlc_cov_arr = dlc_cov*np.ones((n_cams*n_markers*2))\n",
    "    dlc_cov_arr[bad_point_mask] = max_pixel_err # change this to be independent of cam res?\n",
    "    R = np.diag(dlc_cov_arr**2)\n",
    "\n",
    "    # Residual\n",
    "    residual = z_k - h\n",
    "\n",
    "    # Residual Covariance S\n",
    "    S = (H @ P @ H.T) + R\n",
    "    temp = sigma_bound*np.sqrt(np.diag(S)) # if measurement residual is worse than 3 sigma, set residual to 0 and rely on predicted state only\n",
    "    for j in range(0, len(residual), 2):\n",
    "        if np.abs(residual[j])>temp[j] or np.abs(residual[j+1])>temp[j+1]:\n",
    "            residual[j:j+2] = 0\n",
    "            outliers_ignored += 1\n",
    "        \n",
    "    # Kalman Gain\n",
    "    K = P @ H.T @ np.linalg.inv(S)\n",
    "\n",
    "    # Correction\n",
    "    states = states + K @ residual\n",
    "    states_est_hist[i] = states\n",
    "\n",
    "    # Update State Covariance\n",
    "    P = (np.eye(K.shape[0]) - K @ H) @ P\n",
    "    P_est_hist[i] = P\n",
    "    \n",
    "print(\"Outliers ignored:\", outliers_ignored)\n",
    "\n",
    "# Run Kalman Smoother\n",
    "smooth_states_est_hist = states_est_hist.copy()\n",
    "smooth_P_est_hist = P_est_hist.copy()\n",
    "for i in range(n_frames-2, 0, -1):\n",
    "    A = P_est_hist[i] @ F.T @ np.linalg.inv(P_pred_hist[i+1])\n",
    "    smooth_states_est_hist[i] = states_est_hist[i] + A @ (smooth_states_est_hist[i+1] - states_pred_hist[i+1])\n",
    "    smooth_P_est_hist[i] = P_est_hist[i] + A @ (smooth_P_est_hist[i+1] - P_pred_hist[i+1]) @ A.T\n",
    "    \n",
    "print(\"\\nKalman Smoother complete!\\n\")\n",
    "t1 = time()\n",
    "print(\"Optimization took {0:.2f} seconds\\n\".format(t1 - t0))\n",
    "\n",
    "app.stop_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save EKF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = dict(x=states_est_hist[:, :vel_idx],\n",
    "              dx=states_est_hist[:, vel_idx:acc_idx],\n",
    "              ddx=states_est_hist[:, acc_idx:],\n",
    "              smoothed_x=smooth_states_est_hist[:, :vel_idx],\n",
    "              smoothed_dx=smooth_states_est_hist[:, vel_idx:acc_idx],\n",
    "              smoothed_ddx=smooth_states_est_hist[:, acc_idx:]\n",
    "             )\n",
    "app.save_ekf(states, OUT_DIR, scene_fpath, start_frame, dlc_thresh)\n",
    "\n",
    "fig_fpath= os.path.join(OUT_DIR, 'ekf.svg')\n",
    "app.plot_cheetah_states(states['x'], states['smoothed_x'], fig_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the cheetah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = os.path.join(OUT_DIR, 'ekf.pickle')\n",
    "app.plot_cheetah_reconstruction(data_fpath, hide_lure=True, reprojections=False, centered=True, dark_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpaths = [os.path.join(DATA_DIR, 'sba', 'sba.pickle'),\n",
    "               os.path.join(DATA_DIR, 'ekf', 'ekf.pickle'),\n",
    "               os.path.join(DATA_DIR, 'fte', 'fte.pickle')]\n",
    "app.plot_multiple_cheetah_reconstructions(data_fpaths, hide_lure=True, reprojections=False, centered=True, dark_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
